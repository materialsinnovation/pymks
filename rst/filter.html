

<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Filter Example &mdash; PyMKS</title>
    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootswatch-3.1.0/cosmo/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pymks.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.1-dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.1.0/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="../_static/pymks_logo.ico"/>
    <link rel="top" title="PyMKS" href="../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body>


  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><img src="../_static/pymks_logo.png">
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.1-dev</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            <li class="divider-vertical"></li>
            
                <li><a href="INSTALLATION.html">Installation</a></li>
                <li><a href="../EXAMPLES.html">Examples</a></li>
                <li><a href="../API.html">API</a></li>
                <li><a href="https://github.com/openmaterials/pymks/">Github</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">More <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../THEORY.html">Theory</a><ul>
<li class="toctree-l2"><a class="reference internal" href="derivation.html">Derivation of Materials Knowledge Systems Equation using Linear Elasticity</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="CREDITS.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="LICENSE.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="CITATION.html">Citing</a></li>
<li class="toctree-l1"><a class="reference internal" href="REQUIREMENTS.html">Requirements</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12">
      
  <div class="section" id="filter-example">
<h1>Filter Example<a class="headerlink" href="#filter-example" title="Permalink to this headline">Â¶</a></h1>
<p>This example demonstrates the connection between MKS and signal
processing for a 1D filter. It shows that the filter is in fact the same
as the influence coefficients and, thus, applying the <tt class="docutils literal"><span class="pre">predict</span></tt> method
provided by the <tt class="docutils literal"><span class="pre">MKSRegressionModel</span></tt> is in essence just applying a
filter.</p>
<div class="code python highlight-python"><pre>%matplotlib inline
%load_ext autoreload
%autoreload 2

import numpy as np
import matplotlib.pyplot as plt</pre>
</div>
<div class="highlight-python"><pre>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload</pre>
</div>
<p>Here we construct a filter, <span class="math">\(F\)</span>, such that</p>
<div class="math">
\[F\left(x\right) = e^{-|x|} \cos{\left(2\pi x\right)}\]</div>
<p>We want to show that if <span class="math">\(F\)</span> is used to generate sample calibration
data for the MKS, then the calculated influence coefficients are in fact
just <span class="math">\(F\)</span>.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">x0</span> <span class="o">=</span> <span class="o">-</span><span class="mf">10.</span>
<span class="n">x1</span> <span class="o">=</span> <span class="mf">10.</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">F</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">F</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/filter_3_0.png" src="../_images/filter_3_0.png" />
<p>Next we generate the sample data <tt class="docutils literal"><span class="pre">(X,</span> <span class="pre">y)</span></tt> using
<tt class="docutils literal"><span class="pre">scipy.ndimage.convolve</span></tt>. This performs the convolution</p>
<div class="math">
\[p\left[ i \right] = F\left[j\right] X\left[i + j\right]\]</div>
<p>for each sample.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">scipy.ndimage</span>

<span class="n">Nspace</span> <span class="o">=</span> <span class="mi">101</span>
<span class="n">Nsample</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">201</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">Nspace</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">Nsample</span><span class="p">,</span> <span class="n">Nspace</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">scipy</span><span class="o">.</span><span class="n">ndimage</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">F</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;wrap&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>
</pre></div>
</div>
<p>For this problem, a basis is unnecessary as no discretization is
required in order to reproduce the convolution with the MKS. Using the
<tt class="docutils literal"><span class="pre">ContinuousIndicatorBasis</span></tt> with <tt class="docutils literal"><span class="pre">n_states=2</span></tt> is the equivalent of a
non-discretized convolution in space.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">pymks</span> <span class="kn">import</span> <span class="n">MKSRegressionModel</span>
<span class="kn">from</span> <span class="nn">pymks</span> <span class="kn">import</span> <span class="n">ContinuousIndicatorBasis</span>

<span class="n">basis</span> <span class="o">=</span> <span class="n">ContinuousIndicatorBasis</span><span class="p">(</span><span class="n">n_states</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MKSRegressionModel</span><span class="p">(</span><span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">)</span>
</pre></div>
</div>
<p>Fit the model using the data generated by <span class="math">\(F\)</span>.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>To check for internal consistency, we can compare the predicted output
with the original for a few values</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">4</span><span class="p">]</span>
<span class="k">print</span> <span class="n">y_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">4</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python"><pre>[-0.41059557  0.20004566  0.61200171  0.5878077 ]
[-0.41059557  0.20004566  0.61200171  0.5878077 ]</pre>
</div>
<p>With a slight linear manipulation of the coefficients, they agree
perfectly with the shape of the filter, <span class="math">\(F\)</span>.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">F</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">r&#39;$F$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">coeff</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">coeff</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">r&#39;$\alpha$&#39;</span><span class="p">)</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/filter_13_0.png" src="../_images/filter_13_0.png" />
<p>Some manipulation of the coefficients is required to reproduce the
filter. Remember the convolution for the MKS is</p>
<div class="math">
\[p \left[i\right] = \sum_h^{n-1} \alpha_h \left[j\right] m_h \left[i + j\right]\]</div>
<p>However, the <tt class="docutils literal"><span class="pre">MKSRegressionModel</span></tt> solves a modified form of this.
There are always redundant coefficients since</p>
<div class="math">
\[\sum\limits_{h=0}^{n-1} m_h \left[i\right] = 1\]</div>
<p>Thus, the convolution must be rewritten taking this into account. We can
rewrite the convolution as</p>
<div class="math">
\[\begin{split} \begin{split}
p \left[i\right] &amp;= \sum\limits_{h=0}^n \alpha_h \left[j\right] m_h \left[i + j\right] \\
        &amp;= \sum\limits_{h=0}^{n - 2}  \alpha_h \left[j\right] m_h \left[i + j\right] +
           \alpha_{n-1} \left[j\right] \left( I\left[i + j\right] - \sum\limits_{h=0}^{n - 2} m_h \left[i + j\right] \right) \\
        &amp;=  \alpha_{n - 1} \left[ j \right]  I\left[i + j\right] +
           \sum\limits_{h=0}^{n - 2} \left(\alpha_h\left[j\right] - \alpha_{n-1}\left[j\right] \right) m_h\left[i + j\right] \\
        &amp;= \beta + \sum\limits_{h=0}^{n - 2} b_h \left[ j \right] m_h \left[ i + j \right]
\end{split}\end{split}\]</div>
<p>where
<span class="math">\(\beta = \alpha_{n - 1} \left[ j \right]  I\left[i + j\right]\)</span> is
just a constant and <span class="math">\(I\left[i\right] = 1\)</span> for all <span class="math">\(i\)</span>. This
removes the redundancies from the regression. Manipulation of the
<span class="math">\(\beta\)</span> and <span class="math">\(b_0\)</span> demonstrate that the filter is reproduced.</p>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>